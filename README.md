# ğŸš€ Spark Advanced Examples

[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5.0-red.svg)](https://spark.apache.org/)
[![Scala](https://img.shields.io/badge/Scala-2.12+-orange.svg)](https://scala-lang.org/)

**Advanced Spark Code Examples - Connectivity, Streaming, and Big Data Pipelines!** Production-ready Scala examples for Kafka integration, Hive connectivity, database connections, and real-time streaming applications.

---

## ğŸ¯ **Repository Overview**

This repository consolidates **2 major Spark example repositories**:

### ğŸ“š **Core Components:**
1. **ğŸ”— Connectivity Examples** - Kafka, Hive, and Database Integration
2. **âš¡ Streaming Applications** - Real-time Data Processing with Spark Streaming
3. **ğŸ—ï¸ Production Patterns** - Enterprise-scale Spark architectures

---

## ğŸ—ï¸ **Repository Structure**

```
ğŸ“¦ spark-advanced-examples/                 # Advanced Spark Examples
â”œâ”€â”€ ğŸ“– README.md                             # You're reading it!
â”œâ”€â”€
â”œâ”€â”€ ğŸ”— connectivity/                         # External System Integration
â”‚   â”œâ”€â”€ kafka-producer-consumer/             # Kafka messaging examples
â”‚   â”‚   â”œâ”€â”€ HelloProducer.scala              # Kafka producer implementation
â”‚   â”‚   â”œâ”€â”€ HelloConsumer.scala              # Kafka consumer implementation
â”‚   â”‚   â””â”€â”€ HelloProducer_test.scala         # Producer testing
â”‚   â”œâ”€â”€ hive-integration/                    # Hive data warehouse examples
â”‚   â”‚   â”œâ”€â”€ FileToHiveTable.scala            # CSV to Hive table
â”‚   â”‚   â”œâ”€â”€ connectDockerHive.scala          # Docker Hive connectivity
â”‚   â”‚   â””â”€â”€ metastore_db/                    # Hive metastore configuration
â”‚   â””â”€â”€ jdbc-connections/                    # Database connectivity
â”‚       â”œâ”€â”€ MysqlJDBCConnect.scala           # MySQL JDBC connection
â”‚       â””â”€â”€ AppConfigs.scala                 # Configuration management
â”œâ”€â”€
â”œâ”€â”€ âš¡ streaming/                            # Real-time Data Processing
â”‚   â”œâ”€â”€ basic-streaming/                     # Socket-based streaming
â”‚   â”‚   â”œâ”€â”€ streaming_1.scala                # Basic socket streaming
â”‚   â”‚   â”œâ”€â”€ streaming_2.scala                # Advanced socket processing
â”‚   â”‚   â”œâ”€â”€ streaming_3.scala                # Error handling and recovery
â”‚   â”‚   â””â”€â”€ streaming_4.scala                # Streaming transformations
â”‚   â”œâ”€â”€ structured-streaming/               # Structured Streaming API
â”‚   â”‚   â”œâ”€â”€ struct_streaming_1.scala         # Structured streaming basics
â”‚   â”‚   â”œâ”€â”€ struct_streaming_2.scala         # Complex transformations
â”‚   â”‚   â”œâ”€â”€ struct_streaming_3.scala         # Windowing operations
â”‚   â”‚   â””â”€â”€ struct_streaming_4.scala         # State management
â”‚   â””â”€â”€ file-streaming/                      # File-based streaming
â”‚       â”œâ”€â”€ streaming_file.scala             # File stream processing
â”‚       â”œâ”€â”€ inputfolder/                     # Sample input files
â”‚       â””â”€â”€ outputfolder/                    # Generated output
â”œâ”€â”€
â”œâ”€â”€ ğŸ› ï¸ tools/                               # Development utilities
â”‚   â”œâ”€â”€ build.sbt                            # SBT build configuration
â”‚   â”œâ”€â”€ pom.xml                             # Maven build configuration
â”‚   â””â”€â”€ log4j.properties                    # Logging configuration
â”œâ”€â”€
â”œâ”€â”€ ğŸ“š resources/                           # Configuration and data
â”‚   â”œâ”€â”€ AppConfigs.scala                    # Application configurations
â”‚   â””â”€â”€ sample-data/                        # Sample input files
â”œâ”€â”€
â””â”€â”€ ğŸ—„ï¸ archive/                            # Original source preservation
    â”œâ”€â”€ spark-kafka-hive-connctivity-examples/ # Connectivity examples source
    â””â”€â”€ Spark-Streaming--Socket/            # Streaming examples source
```

---

## ğŸ¯ **Technology Coverage**

### **ğŸ”— Connectivity Layer**

#### **Apache Kafka Integration**
- **Message Production:** High-throughput data publishing
- **Consumer Patterns:** Real-time data consumption and processing
- **Testing Frameworks:** Producer/consumer validation strategies

#### **Apache Hive Integration**
- **Data Warehousing:** Table creation from files
- **Metastore Management:** Hive catalog and metadata operations
- **Docker Connectivity:** Containerized Hive deployments

#### **Database Connectivity**
- **JDBC Integration:** MySQL and relational databases
- **Connection Management:** Connection pooling and configuration
- **Error Handling:** Robust database failure recovery

### **âš¡ Streaming Layer**

#### **Socket-Based Streaming**
- **Network Streaming:** TCP socket data ingestion
- **Processing Patterns:** Real-time data transformations
- **Fault Tolerance:** Stream processing reliability

#### **Structured Streaming**
- **DataFrame Operations:** SQL-like streaming queries
- **Windowing Functions:** Time-based aggregations
- **State Management:** Persistent streaming state

#### **File Streaming**
- **Directory Monitoring:** Real-time file system changes
- **JSON Processing:** Structured data formats
- **Checkpointing:** Stream processing recovery

---

## ğŸ› ï¸ **Setup & Requirements**

### **Prerequisites**
```bash
# Apache Spark 3.0+
# Scala 2.12+
# Java 8+
# Maven/Gradle or SBT
```

### **External Dependencies**
- **Kafka:** For messaging examples
- **MySQL:** For database connectivity
- **Hive:** For warehouse examples
- **Docker:** For containerized services

### **Running the Examples**

#### **Kafka Examples**
```bash
# Start Kafka cluster
docker run -d --name kafka -p 9092:9092 spotify/kafka

# Run producer example
sbt "runMain org.example.HelloProducer"

# Run consumer in another terminal
sbt "runMain org.example.HelloConsumer"
```

#### **Streaming Examples**
```bash
# Basic socket streaming
sbt "runMain streaming.SocketStreaming"

# Structured streaming
sbt "runMain streaming.StructuredStreaming"

# File streaming
sbt "runMain streaming.FileStreaming"
```

---

## ğŸ¯ **Learning Outcomes**

After exploring these examples, you'll understand:

### **ğŸ”— Enterprise Integration**
- **Big Data Ecosystems:** Connecting Spark with Kafka, Hive, databases
- **Data Pipelines:** Building reliable data flow architectures
- **Scalability Patterns:** Distributed system design principles

### **âš¡ Real-Time Processing**
- **Streaming Architectures:** Real-time data processing patterns
- **Fault Tolerance:** Resilient stream processing
- **Performance Tuning:** Optimizing throughput and latency

### **ğŸ­ Production Excellence**
- **Configuration Management:** Enterprise application configs
- **Logging & Monitoring:** Production observability patterns
- **Error Handling:** Robust failure recovery strategies

---

## ğŸ“ **Examples Included**

### **Producer-Consumer Patterns**
- Kafka message publishing with varying throughput
- Consumer group management and offset handling
- Error recovery and dead letter queues

### **Data Warehouse Integration**
- Hive table creation from CSV and JSON files
- Partitioned table management
- Query optimization and performance tuning

### **Streaming Transformations**
- Complex event processing pipelines
- Time-series data aggregation
- Machine learning on streaming data

---

## ğŸ† **Professional Value**

This repository demonstrates:

- **ğŸš€ Scalability:** Production-ready distributed systems
- **ğŸ”’ Reliability:** Error handling and fault tolerance
- **ğŸ“Š Performance:** Optimized data processing pipelines
- **ğŸ—ï¸ Architecture:** Enterprise-scale application patterns

---

## ğŸ¤ **Contributions & Learning**

These examples serve as:

- **ğŸš€ Starting Points:** For your Spark projects
- **ğŸ“š Learning Resources:** Understanding advanced concepts
- **ğŸ’¼ Portfolio Pieces:** Demonstrating production capabilities
- **ğŸ¤ Community Assets:** Shared knowledge and patterns

---

## ğŸ“ **Support & Documentation**

### **Official Documentation**
- [Spark Streaming Programming Guide](https://spark.apache.org/docs/latest/streaming-programming-guide.html)
- [Structured Streaming Documentation](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Spark SQL Documentation](https://spark.apache.org/docs/latest/sql-programming-guide.html)

---

*"Spark is not just a framework - it's a way of thinking about distributed data processing. These examples show you how to build systems that scale beyond imagination."*

**âš¡ Happy Spark Engineering! May your pipelines always stream smoothly.** ğŸ®
